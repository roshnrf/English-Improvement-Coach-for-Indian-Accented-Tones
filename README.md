# English Improvement Coach for Indian-Accented Tones ğŸ—£ï¸ğŸ‡®ğŸ‡³

A real-time AI-based English coaching tool for Indian-accented speakers. This system takes user voice input, transcribes it using **OpenAI Whisper** and **HuBERT**, improves grammar with **GPT-3.5**, and plays back the corrected sentence using **Google Text-to-Speech** â€” creating a conversational loop via a **Gradio interface**.

---

## ğŸ¯ Goal

Assist Indian English speakers in improving pronunciation and grammar in real-time by:
- Analyzing spoken input
- Generating corrected transcriptions
- Synthesizing native-like audio output

---

## ğŸ§© Key Technologies

| Component           | Tool Used                                                    |
|---------------------|-------------------------------------------------------------|
| ASR (Speech to Text)| OpenAI Whisper, HuBERT                                      |
| Grammar Correction  | GPT-3.5 via HuggingFace (`prithivida/grammar_error_correcter_v1`) |
| TTS (Text to Speech)| Google Cloud TTS (gTTS alternative)                         |
| UI                  | Gradio (for voice-to-voice interaction)                     |
| Evaluation          | Word Error Rate (WER) via `jiwer`                           |

---

## ğŸ” How It Works

### ğŸ“Œ Architecture Overview

![Architecture Diagram](assets/architecture_diagram.png)

The process flow is:

1. ğŸ™ï¸ **Audio input** from Svarah (Indian-accented English)
2. ğŸ”Š Transcribed via **Whisper + HuBERT**
3. âœï¸ Text corrected using **GPT-3.5 grammar model**
4. ğŸ” Converted back into native-style audio via **Google TTS**

---

## ğŸ“ Dataset

We used the **Svarah** dataset â€” a high-quality Indian-accented English speech dataset featuring audio clips across diverse regional accents.

- ğŸ”— [Svarah on Hugging Face](https://huggingface.co/datasets/ai4bharat/Svarah)
- ğŸ“„ Citation available in the section below
- ğŸ’¾ Format: `.wav` audio files
- ğŸ§  Suitable for ASR, pronunciation evaluation, and accent-specific NLP

---

## ğŸ› ï¸ Code Highlights

```python
# Transcribe using Whisper and HuBERT
transcription_whisper = transcribe_whisper(audio_path)
transcription_hubert = transcribe_hubert(audio_path)

# Correct grammar using GPT-3.5 model
corrected_text = correct_text(transcription_whisper)

# Convert to native-sounding audio
text_to_speech(corrected_text, "output.mp3")

# Evaluate accuracy using Word Error Rate
accuracy = calculate_accuracy(ground_truth, corrected_text)
```

---

## ğŸ“Š Sample Output

```
Original:     so because when I have to make payment I do it by Apple Pay
Whisper:      So because when I have to make payment, I do it by April pay.
HuBERT:       SO BECAUSE WHEN I HAVE TO MAKE PAYMENT I DO IT BY A PULPET
Corrected Whisper: So when I have to make payment, I do it by April pay.
Corrected HuBERT:  When I have to make payment I do it by a pulpet.
Whisper Accuracy: 85.71%
HuBERT Accuracy:  71.43%
```

âœ”ï¸ Outputs saved as:
- `whisper_output.mp3`
- `hubert_output.mp3`

---

## ğŸš§ Project Status & Vision

This project currently serves as a **working base prototype**. It runs locally and demonstrates the core functionality of:

- Transcribing Indian-accented speech
- Correcting grammar using an LLM
- Converting improved sentences to speech

### ğŸ› ï¸ Development Status:
- The **voice-to-voice pipeline** works end-to-end locally.
- Not yet packaged as a full-fledged app or web service.
- Gradio integration is in progress for interactive demos.

### ğŸ¯ Future Vision:
We aim to evolve this into an **accessible and user-friendly AI-powered application** that helps Indian English speakers across regions improve spoken English fluency, grammar, and pronunciation in real time â€” especially useful for learners, students, professionals, and second-language speakers.

> This tool is designed with inclusivity and practicality in mind â€” bridging tech with language learning.

---

## ğŸ”® Future Work

- Accent-specific fine-tuning of models (e.g., region-wise Svarah subsets)
- Add multilingual support (e.g., Hinglish, Tamil-English)
- Use Whisper Large + Tortoise TTS for better voice realism
- Deploy to Hugging Face Spaces or Streamlit Cloud for public demo

---

## ğŸ“š Research Inspiration

This project was inspired by literature on inclusive ASR systems and the need for accent-aware AI tools. Key references include:
- *Evaluating Whisper ASR Across Accents* â€“ University of Cambridge
- *Exploring Integrations of LLMs in ASR* â€“ Peking University
- *Svarah Dataset Paper*
- *BERT and HuBERT papers on contextual embeddings for speech*
- *Speech Recognition Using Deep Neural Networks* â€“ University of Sharjah

---

## ğŸ‘¨â€ğŸ’» Contributors

- **Roshan A Rauof** 
- **Amritha K** 
- **Reem Fariha** 
- **Shifana Mehar** 

---

## ğŸ“Œ Tags

`#ASR` `#SpeechToText` `#IndianAccentAI` `#LLM` `#Whisper` `#gTTS` `#Gradio` `#XAI` `#GPT35`

---

## ğŸ“– Citation

If you use any of the tools or datasets in this project, please consider citing the following resources:

---

### ğŸ“Œ Svarah Dataset

**Paper:**  
[Svarah: Evaluating English ASR Systems on Indian Accents (INTERSPEECH 2023)](https://www.isca-archive.org/interspeech_2023/javed23_interspeech.pdf)

```bibtex
@inproceedings{DBLP:conf/interspeech/JavedJNSNRBKK23,
  author       = {Tahir Javed and
                  Sakshi Joshi and
                  Vignesh Nagarajan and
                  Sai Sundaresan and
                  Janki Nawale and
                  Abhigyan Raman and
                  Kaushal Santosh Bhogale and
                  Pratyush Kumar and
                  Mitesh M. Khapra},
  title        = {Svarah: Evaluating English {ASR} Systems on Indian Accents},
  booktitle    = {{INTERSPEECH}},
  pages        = {5087--5091},
  publisher    = {{ISCA}},
  year         = {2023}
}
```

---

### ğŸ“Œ OpenAI Whisper

**Paper:** [Robust Speech Recognition via Large-Scale Weak Supervision (2022)](https://cdn.openai.com/papers/whisper.pdf)

```bibtex
@misc{radford2022whisper,
  title        = {Robust Speech Recognition via Large-Scale Weak Supervision},
  author       = {Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Jonas Schneider},
  year         = {2022},
  publisher    = {OpenAI},
  url          = {https://cdn.openai.com/papers/whisper.pdf}
}
```

---

### ğŸ“Œ HuBERT (Facebook AI)

**Paper:** [HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units](https://arxiv.org/abs/2106.07447)

```bibtex
@article{hsu2021hubert,
  title   = {HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units},
  author  = {Wei-Ning Hsu and Benjamin Bolte and Yao-Hung Hubert Tsai and Kushal Lakhotia and Ruslan Salakhutdinov and Abdelrahman Mohamed},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year    = {2021},
  url     = {https://arxiv.org/abs/2106.07447}
}
```

---

### ğŸ“Œ Grammar Correction Model

Model: [`prithivida/grammar_error_correcter_v1`](https://huggingface.co/prithivida/grammar_error_correcter_v1)  
Author: Prithiviraj Damodaran (Hugging Face)

---

### ğŸ“Œ Google TTS

Docs: [Google Cloud Text-to-Speech API](https://cloud.google.com/text-to-speech/docs)  
No formal citation required, but check usage guidelines.
